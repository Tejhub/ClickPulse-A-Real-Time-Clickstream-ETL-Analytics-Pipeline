ğŸš€ ClickPulse â€“ Real-Time Clickstream Analytics Pipeline

ClickPulse is an end-to-end real-time clickstream analytics project designed to simulate and process live user behavior data in an e-commerce environment. The project replays a real e-commerce clickstream dataset as streaming events using Apache Kafka and processes them in real time using Spark Structured Streaming (PySpark), following an industry-standard Bronzeâ€“Silverâ€“Gold data lake architecture.

ğŸ§  Project Overview  

Modern applications generate massive volumes of user interaction data every second. ClickPulse demonstrates how such data can be ingested, processed, and prepared for analytics in real time.  

This project focuses on:

Real-time event ingestion  
Stream processing  
Data lake design  
Analytics-ready data preparation  

ğŸ”„ Architecture & Workflow

E-commerce Dataset  
        â†“  
Kafka (Replay Producer â€“ Real-Time Events)  
        â†“  
Spark Structured Streaming (PySpark)  
        â†“  
Bronze Layer (Raw Events)  
        â†“  
Silver Layer (Cleaned & Structured Data)  
        â†“  
Gold Layer (Aggregated Metrics)  
        â†“  
     Tableau   

ğŸ›  Tech Stack

- Apache Kafka â€“ Real-time event streaming
- Apache Spark Structured Streaming (PySpark) â€“ Stream processing
- Spark SQL â€“ Data transformations
- Python â€“ Data handling and replay producer
- Parquet â€“ Data lake storage format
- Tableau â€“ Data visualization (optional)
- Local Setup â€“ Cost-efficient, cloud-ready design

â–¶ï¸ How to Run the Project (Local)  

1ï¸âƒ£ Prerequisites  

Java 8 or 11  
Python 3.8+  
Apache Kafka  
Apache Spark  

Required Python packages:

pip install pandas kafka-python pyspark

2ï¸âƒ£ Start Kafka  
zookeeper-server-start.sh config/zookeeper.properties  
kafka-server-start.sh config/server.properties  


Create topic:

kafka-topics.sh --create \
  --topic clickpulse_events \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

3ï¸âƒ£ Start Spark Streaming  
spark-submit spark/streaming/clickpulse_streaming_job.py

4ï¸âƒ£ Start Replay Producer  
python kafka/producer/clickstream_replay_producer.py  

Streaming data will start flowing into the Bronze layer.

5ï¸âƒ£ Build Silver Layer  
spark-submit spark/batch/bronze_to_silver.py

6ï¸âƒ£ Build Gold Layer  
spark-submit spark/batch/silver_to_gold.py

ğŸ‘¨â€ğŸ’» Author  

Tejas Gurav  
Aspiring Data Engineer | Big Data | Streaming Systems
